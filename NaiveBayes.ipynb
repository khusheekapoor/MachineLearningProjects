{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 3 - Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Khushee Kapoor\n",
    "\n",
    "Last Updated: 3/4/22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we have imported the following libraries:\n",
    "\n",
    "- NumPy: to work with the data\n",
    "- Pandas: to manipulate the dataframe\n",
    "- MatPlotLib: for data visualization\n",
    "- Seaborn: for data visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we read the dataset and store it into a dataframe using the read_csv() function from the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "df = pd.read_csv('Womens Clothing E-Commerce Reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we view the first few rows of the dataframe to get a glimpse of it. To do this, we use the head() function from the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Recommended IND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                      NaN   \n",
       "1           1         1080   34                      NaN   \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5   \n",
       "2  I had such high hopes for this dress and reall...       3   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5   \n",
       "4  This shirt is very flattering to all due to th...       5   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name   Category  \\\n",
       "0                        0       Initmates        Intimate  Intimates   \n",
       "1                        4         General         Dresses    Dresses   \n",
       "2                        0         General         Dresses    Dresses   \n",
       "3                        0  General Petite         Bottoms      Pants   \n",
       "4                        6         General            Tops    Blouses   \n",
       "\n",
       "   Recommended IND  \n",
       "0                1  \n",
       "1                1  \n",
       "2                0  \n",
       "3                1  \n",
       "4                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Preprocessing Pipeline\n",
    "\n",
    "**a. Find any null values are present or not, If present remove those data.**\n",
    "\n",
    "**b. Remove the data that have less than 5 reviews.**\n",
    "\n",
    "**c. Clean the data and remove the special characters and replace the contractions with its expansion. Convert the uppercase character to lower case. Also, remove the punctuations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve Question 1a, we use the isnull() function from the Pandas library and then sum over them using the sum() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                    0\n",
       "Clothing ID                   0\n",
       "Age                           0\n",
       "Title                      3810\n",
       "Review Text                 845\n",
       "Rating                        0\n",
       "Positive Feedback Count       0\n",
       "Division Name                14\n",
       "Department Name              14\n",
       "Category                     14\n",
       "Recommended IND               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are missing values in the Title, Review Text, Division Name, Department Name, and Category columns. To remove them, we use the dropna() function from the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve Question 1b, we create a new column to store the count of reviews of each product. To do this, we iterate over the unique clothing ids using the unique() function from the Pandas library, then use the loc() function to locate the every unqiue id and the value_counts() function to store it's count. Then we use logical splicing to filter out the columns having less than 5 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column\n",
    "df['number'] = 0\n",
    "\n",
    "# storing the count of every clothing id\n",
    "for cloth in df['Clothing ID'].unique():\n",
    "    df.loc[df['Clothing ID']==cloth, 'number'] = df['Clothing ID'].value_counts()[cloth]\n",
    "\n",
    "# filtering out the products with less than 5 reviews\n",
    "df = df[df.number>=5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve Question 1c, we first create a dictionary with all the contractions and their expansions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary with contractions and their expansions\n",
    "contractions = {\n",
    "\"a'ight\":\"alright\",\n",
    "\"ain't\":\"are not\",\n",
    "\"amn't\":\"am not\",\n",
    "\"aren't\":\"are not\",\n",
    "\"can't\":\"cannot\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\":\"could have\",\n",
    "\"couldn't\":\"could not\",\n",
    "\"couldn't've\":\"could not have\",\n",
    "\"daren't\":\"dare not\",\n",
    "\"daresn't\":\"dare not\",\n",
    "\"dasn't\":\"dare not\",\n",
    "\"didn't\":\"did not\",\n",
    "\"doesn't\":\"does not\",\n",
    "\"don't\":\"do not\",\n",
    "\"everybody's\":\"everybody is\",\n",
    "\"everyone's\":\"everyone is\",\n",
    "\"giv'n\":\"given\",\n",
    "\"gonna\":\"going to\",\n",
    "\"gon't\":\"go not\", \n",
    "\"gotta\":\"got to\",\n",
    "\"hadn't\":\"had not\",\n",
    "\"had've\":\"had have\",\n",
    "\"hasn't\":\"has not\",\n",
    "\"haven't\":\"have not\",\n",
    "\"he'd\":\"he had\", \n",
    "\"he'll\":\"he will\",\n",
    "\"he's\":\"he is\",\n",
    "\"here's\":\"here is\",\n",
    "\"how'd\":\"how did\",\n",
    "\"how'll\":\"how will\",\n",
    "\"how're\":\"how are\",\n",
    "\"how's\":\"how is\",\n",
    "\"I'd\":\"I had\",\n",
    "\"I'd've\":\"I would have\",\n",
    "\"I'd'nt\":\"I would not\",\n",
    "\"I'd'nt've\":\"I would not have\",\n",
    "\"I'll\":\"I will\",\n",
    "\"I'm\":\"I am\",\n",
    "\"I've\":\"I have\",\n",
    "\"isn't\":\"is not\",\n",
    "\"it'd\":\"it would\",\n",
    "\"it'll\":\"it will\",\n",
    "\"it's\":\"it is\",\n",
    "\"let's\":\"let us\",\n",
    "\"ma'am\":\"madam\",\n",
    "\"mayn't\":\"may not\",\n",
    "\"may've\":\"may have\",\n",
    "\"mightn't\":\"might not\",\n",
    "\"might've\":\"might have\",\n",
    "\"mustn't\":\"must not\",\n",
    "\"mustn't've\":\"must not have\",\n",
    "\"must've\":\"must have\",\n",
    "\"needn't\":\"need not\",\n",
    "\"needn't've\":\"need not have\",\n",
    "\"o'clock\":\"of the clock\",\n",
    "\"oughtn't\":\"ought not\",\n",
    "\"oughtn't've\":\"ought not have\",\n",
    "\"shan't\":\"shall not\",\n",
    "\"she'd\":\"she would\",\n",
    "\"she'll\":\"she will\",\n",
    "\"she's\":\"she is\",\n",
    "\"should've\":\"should have\",\n",
    "\"shouldn't\":\"should not\",\n",
    "\"shouldn't've\":\"should not have\",\n",
    "\"somebody's\":\"somebody is\",\n",
    "\"someone's\":\"someone is\",\n",
    "\"something's\":\"something is\",\n",
    "\"so're\":\"so are\",\n",
    "\"so’s\":\"so is\",\n",
    "\"so’ve\":\"so have\",\n",
    "\"that'll\":\"that will\",\n",
    "\"that're\":\"that are\",\n",
    "\"that's\":\"that is\",\n",
    "\"that'd\":\"that would\",\n",
    "\"there'd\":\"there would\",\n",
    "\"there'll\":\"there will\",\n",
    "\"there're\":\"there are\",\n",
    "\"there's\":\"there is\",\n",
    "\"these're\":\"these are\",\n",
    "\"these've\":\"these have\",\n",
    "\"they'd\":\"they would\",\n",
    "\"they'll\":\"they will\",\n",
    "\"they're\":\"they are\",\n",
    "\"they've\":\"they have\",\n",
    "\"this's\":\"this is\",\n",
    "\"those're\":\"those are\",\n",
    "\"those've\":\"those have\",\n",
    "\"to've\":\"to have\",\n",
    "\"wasn't\":\"was not\",\n",
    "\"we'd\":\"we would\",\n",
    "\"we'd've\":\"we would have\",\n",
    "\"we'll\":\"we will\",\n",
    "\"we're\":\"we are\",\n",
    "\"we've\":\"we have\",\n",
    "\"weren't\":\"were not\",\n",
    "\"what'd\":\"what did\",\n",
    "\"what'll\":\"what will\",\n",
    "\"what're\":\"what are\",\n",
    "\"what's\":\"what is\",\n",
    "\"what've\":\"what have\",\n",
    "\"when's\":\"when is\",\n",
    "\"where'd\":\"where did\",\n",
    "\"where'll\":\"where will\",\n",
    "\"where're\":\"where are\",\n",
    "\"where's\":\"where is\",\n",
    "\"where've\":\"where have\",\n",
    "\"which'd\":\"which would\",\n",
    "\"which'll\":\"which will\",\n",
    "\"which're\":\"which are\",\n",
    "\"which's\":\"which is\",\n",
    "\"which've\":\"which have\",\n",
    "\"who'd\":\"who would\",\n",
    "\"who'd've\":\"who would have\",\n",
    "\"who'll\":\"who will\",\n",
    "\"who're\":\"who are\",\n",
    "\"who's\":\"who is\",\n",
    "\"who've\":\"who have\",\n",
    "\"why'd\":\"why did\",\n",
    "\"why're\":\"why are\",\n",
    "\"why's\":\"why is\",\n",
    "\"won't\":\"will not\",\n",
    "\"would've\":\"would have\",\n",
    "\"wouldn't\":\"would not\",\n",
    "\"wouldn't've\":\"would not have\",\n",
    "\"y'at\":\"you at\",\n",
    "\"yes’m\":\"yes madam\",\n",
    "\"you'd\":\"you would\",\n",
    "\"you'll\":\"you will\",\n",
    "\"you're\":\"you are\",\n",
    "\"you've\":\"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a custom made function to convert the contractions to expansions. This function loops over the previously created dictionary and uses the replace() function from the string library to replace the contractions with the expansions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom made function to convert contraction to expansion\n",
    "def cont_to_exp(x):\n",
    "    if type(x) is str:\n",
    "        x = x.replace('\\\\','')\n",
    "        for key in contractions:\n",
    "            value = contractions[key]\n",
    "            x = x.replace(key, value)\n",
    "        return x\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we apply the function on every observation in the review and title column. To do that, we use the apply() function from the Pandas library and the lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting contraction to expansion in every row of the review and title column\n",
    "df['Review Text'] = df['Review Text'].apply(lambda x:cont_to_exp(x))\n",
    "df['Title'] = df['Title'].apply(lambda x:cont_to_exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a custom made function to convert upper case to lower case. This function implements the lower() function from the string package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom made function to convert upper case to lower\n",
    "def upper_to_lower(x):\n",
    "    if type(x) is str:\n",
    "        return x.lower()\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we apply the function on every observation in the review and title column. To do that, we use the apply() function from the Pandas library and the lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting upper case to lower from every row of the review and title column\n",
    "df['Review Text'] = df['Review Text'].apply(lambda x:upper_to_lower(x))\n",
    "df['Title'] = df['Title'].apply(lambda x:upper_to_lower(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a custom made function to remove the punctuations. This function loops over every punctutation in the string.punctuation constant from the string library and use the replace() function to replace them with blanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom made function to remove punctuations\n",
    "import string\n",
    "def remove_punctuations(text):\n",
    "    if type(text) is str:\n",
    "        for p in string.punctuation:\n",
    "            text = text.replace(p, '')\n",
    "        return text\n",
    "    else:\n",
    "        return text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we apply the function on every observation in the review and title column. To do that, we use the apply() function from the Pandas library and the lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing punctuations from every row of the review and title column\n",
    "df['Review Text'] = df['Review Text'].apply(lambda x:remove_punctuations(x))\n",
    "df['Title'] = df['Title'].apply(lambda x:remove_punctuations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a custom made function to remove the special characters. This function loops over every character from a custom made string containing all special characters and use the replace() function to replace them with blanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom made function to remove special characters\n",
    "def remove_special_chars(text):\n",
    "    special_chars = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    if type(text) is str:\n",
    "        for p in special_chars:\n",
    "            text = text.replace(p, '')\n",
    "        return text\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we apply the function on every observation in the review and title column. To do that, we use the apply() function from the Pandas library and the lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing special characters from every row of the review and title column\n",
    "df['Review Text'] = df['Review Text'].apply(lambda x:remove_special_chars(x))\n",
    "df['Title'] = df['Title'].apply(lambda x:remove_special_chars(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further analyze the sentiment regarding the product, we use the TextBlob package to calculate the polarity of the title and the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the text blob package\n",
    "from textblob import TextBlob\n",
    "\n",
    "# computing the polarity of the title and review text\n",
    "df['polarity_title'] = df['Title'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df['polarity_review'] = df['Review Text'].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Separate the columns into dependent and independent variables (or features and labels). Then you split those variables into train and test sets (80:20)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve Question 2, we first drop all the irrelevant columns using the drop() function from the Pandas library. These variables include identifiers, and the newly created number column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the irrelevant columns\n",
    "df = df.drop(columns=['Unnamed: 0', 'Clothing ID', 'number', 'Department Name', 'Division Name', 'Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we split the data into independent variables (x) and independent variable (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into independent and dependent variables\n",
    "x = df.drop(columns=['Recommended IND'])\n",
    "y = df['Recommended IND']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the train_test_split() function from the sklearn library and divide the dataset into training and testing sets. We set the train_size parameter to 0.8 to ensure that 80% of the dataset is put into training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diving the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=105)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we segregate the numerical and categorical columns to easily perform the appropriate preprocessing on the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the numerical columns\n",
    "numerical_cols = [cname for cname in x.columns if x[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# selecting the categorical columns\n",
    "categorical_cols = [cname for cname in x.columns if x[cname].dtype == 'object']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Apply the Naïve Bayes Classification Algorithm on Sentiment category to predict if item is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve Question 3, we form the following pipeline:\n",
    "\n",
    "                                      Independent Variables\n",
    "                                    ___________|__________\n",
    "                                   |                      |\n",
    "                               Numerical             Categorical\n",
    "                                   |                      |\n",
    "                                Scaling              Vectorizing\n",
    "                                   |                      |\n",
    "                                   |               One Hot Encoding\n",
    "                                   |______________________|\n",
    "                                               |\n",
    "               Dependent Variable -- Naive Bayes Classifier\n",
    "                                               |\n",
    "                                             Output\n",
    "\n",
    "To do this, we use the following libraries:\n",
    "\n",
    "- Pipeline: to create the pipeline\n",
    "- ColumnTransformer: to aggregrate the preprocessing steps for the numerical and categorical columns\n",
    "- RobustScaler: to scale the numerical values\n",
    "- CountVectorizer: to vectorize the text and generate the top 10 unigrams and bigrams\n",
    "- OneHotEncoder: to one-hot-encode the categorical values\n",
    "- GaussianNB: to build the naive bayes classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries for preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# scaling the numerical columns \n",
    "numerical_transformer = Pipeline(steps = [\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# vectorizing and one-hot encoding the categorical columns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', CountVectorizer(stop_words='english', ngram_range=(1,2), max_features=10)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols),\n",
    "      ])\n",
    "\n",
    "# building model for prediction\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "\n",
    "# bundle preprocessing and modeling code in a pipeline\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                              ('model', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following that, we fit the pipeline with the training data using the fit() function from the SKLearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['Age', 'Rating',\n",
       "                                                   'Positive Feedback Count',\n",
       "                                                   'polarity_title',\n",
       "                                                   'polarity_review']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer(max_features=10,\n",
       "                                                                                   ngram_range=(1,\n",
       "                                                                                                2),\n",
       "                                                                                   stop_words='english')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  [])])),\n",
       "                ('model', GaussianNB())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the training data \n",
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Tabulate accuracy in terms of accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve Question 4, we use the score(), precision_score(), recall_score(), and f1_score() functions from the SKLearn library to calculate the accuracy, precision, recall, and f1 scores on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.47%\n",
      "Precision: 97.69%\n",
      "Recall: 92.97%\n",
      "F1 Score: 95.27%\n"
     ]
    }
   ],
   "source": [
    "# importing libraries for obtaining evaluation metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# computing and printing the accuracy\n",
    "print(str.format('Accuracy: {:.2f}%', pipe.score(x_test, y_test)*100))\n",
    "\n",
    "# predicting the value of y from the testing set\n",
    "y_pred = pipe.predict(x_test)\n",
    "\n",
    "# computing and printing the precision\n",
    "print(str.format('Precision: {:.2f}%', precision_score(y_test, y_pred)*100))\n",
    "\n",
    "# computing and printing the recall\n",
    "print(str.format('Recall: {:.2f}%', recall_score(y_test, y_pred)*100))\n",
    "\n",
    "# computing and printing the f1 score\n",
    "print(str.format('F1 Score: {:.2f}%', f1_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, all the scores are very high. This means that the model performs really well on the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
